\documentclass[a4paper,10pt,fleqn]{article}
\usepackage[dvipdfmx]{graphicx}
\title{{\Huge Capstone Project}}%%% \\Machine Learning Engineer Nanodegree}

\author{Ryosuke Honda}
\date{\today}
\begin{document}
\maketitle

\section{Definition}

\input{Tex_Section1/Project_Overview}
\input{Tex_Section1/Problem_Statement}
\input{Tex_Section1/Metrics}


\section{Analysis}

\input{Tex_Section2/Data_Exploration}
\input{Tex_Section2/Exploratory_Visualization}
\input{Tex_Section2/Algorithms_and_Techniques}
\input{Tex_Section2/Benchmark}


\section{Methodology}
\subsection{Data Preprocessing}
All preprocessing steps have been clearly documented. Abnormalities or characteristics about the data or input that needed to be addressed have been corrected. If no data preprocessing is necessary, it has been clearly justified.

Apart from the models of image processing or computer vision, CNN doesn't need complex preprocessing.However,when analyzing the data, data preprocessing plays a crucial role. One of the first steps is the normalization of the data. This step is essential when dealing with parameters of different units and scales. In this dataset, pixel values range from 0 to 255. I process normalization to this dataset.
Normalization scales all numeric variables in the range of [0,1].The formula is given below.

\begin{eqnarray}
x_{new}=\frac{x-x_{min}}{x_{max}-x_{min}}
\end{eqnarray}

The minimum pixel value is 0 and maximum pixel value is 255. Therefore, I normalized the data by following.



\begin{eqnarray}
x_{new}=\frac{x}{255}
\end{eqnarray}

\subsection{Implementation}
The process for which metrics, algorithms, and techniques were implemented with the given datasets or input data has been thoroughly documented. Complications that occurred during the coding process are discussed.






\subsection{Refinement}
The process of improving upon the algorithms and techniques used is clearly documented. Both the initial and final solutions are reported, along with intermediate solutions, if necessary.

Finding the optimal parameters for deep learning is quite difficult though it is important. When it comes to typical machine learning algorithm(Decision tree, Support Vector Machine etc.),grid search is taken to search the optimal parameters. However, it's almost impossible to apply grid search in deep learning because of the computational time. Therefore, other methods are indispensable. A good choice is Bayesian optimization, which has been shown to outperform other state of the art global optimization algorithms on a number of challenging optimization benchmark functions.




\section{Result}
\subsection{Model Evaluation and Validation}
The final model’s qualities — such as parameters — are evaluated in detail. Some type of analysis is used to validate the robustness of the model’s solution.

From the result of Bayesian Optimization, I chose ----- as the final model parameters.



\subsection{Justification}
The final results are compared to the benchmark result or threshold with some type of statistical analysis. Justification is made as to whether the final model and solution is significant enough to have adequately solved the problem.




\section{Conclusion}
\subsection{Free-Form Visualization}
A visualization has been provided that emphasizes an important quality about the project with thorough discussion. Visual cues are clearly defined.

\subsection{Reflection}
Student adequately summarizes the end-to-end problem solution and discusses one or two particular aspects of the project they found interesting or difficult.

\subsection{Improvement}
Discussion is made as to how one aspect of the implementation could be improved. Potential solutions resulting from these improvements are considered and compared/contrasted to the current solution.






\end{document}