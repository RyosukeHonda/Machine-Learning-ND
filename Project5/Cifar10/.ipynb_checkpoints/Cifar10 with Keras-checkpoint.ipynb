{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    " # Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/honda/anaconda/lib/python2.7/site-packages/pandas/computation/__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n",
      "/Users/honda/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import cPickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpickle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(f):\n",
    "    fo = open(f,'rb')\n",
    "    d = cPickle.load(fo)\n",
    "    fo.close()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_cifar10(dir):\n",
    "    train_data=[]\n",
    "    train_target=[]\n",
    "    \n",
    "    for i in range(1,6):\n",
    "        d = unpickle('%s/data_batch_%d' %(dir,i))\n",
    "        train_data.extend(d['data'])\n",
    "        train_target.extend(d['labels'])\n",
    "        \n",
    "    d = unpickle('%s/test_batch' %(dir))\n",
    "    test_data = d['data']\n",
    "    test_target = d['labels']\n",
    "    \n",
    "    train_data = np.array(train_data,dtype=np.float32)\n",
    "    train_target = np.array(train_target,dtype=np.int32)\n",
    "    test_data = np.array(test_data,dtype=np.float32)\n",
    "    test_target = np.array(test_target,dtype=np.int32)\n",
    "    \n",
    "    train_data /=255.0\n",
    "    test_data /=255.0\n",
    "    \n",
    "    return train_data,test_data,train_target,test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = load_cifar10(\"cifar-10-batches-py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((len(X_train),3,32,32))\n",
    "X_test = X_test.reshape((len(X_test),3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "nb_classes =10\n",
    "\n",
    "#Change the target values into one-hot vectors \n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test\n",
    "#y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Deep Learning Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,MaxPooling2D,Flatten\n",
    "from keras.layers import Convolution2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD,Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "  768/50000 [..............................] - ETA: 102s - loss: 2.2579 - acc: 0.1576"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nb_classes = 10\n",
    "nb_epoch = 3\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32,3,3,border_mode='same',input_shape=(3,32,32)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(output_dim=512,input_dim=7200,activation='relu'))\n",
    "model.add(Dense(output_dim=10,input_dim=512))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,y_train,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              validation_data=(X_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_train)\n",
    "\n",
    "    # fit the model on the batches generated by datagen.flow()\n",
    "model.fit_generator(datagen.flow(X_train, y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        samples_per_epoch=X_train.shape[0],\n",
    "                        nb_epoch=nb_epoch,\n",
    "                        validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils.visualize_util import plot\n",
    "plot(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Convolution2D(32,3,3,border_mode='same',input_shape=(3,32,32)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model2.add(Convolution2D(32,3,3,border_mode='same'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model2.add(Convolution2D(32,3,3,border_mode='same'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model2.add(Convolution2D(32,3,3,border_mode='same'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model2.add(Convolution2D(32,3,3,border_mode='same'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(output_dim=512,input_dim=7200,activation='relu'))\n",
    "model2.add(Dense(output_dim=10,input_dim=512))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.fit(X_train,y_train,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              validation_data=(X_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model2).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "key",
   "current_citInitial": 1,
   "eqLabelWithNumbers": false,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
